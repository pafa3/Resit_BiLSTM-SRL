{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f6815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow.keras import Sequential, Model, Input, optimizers\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b8c549-3fc0-4530-abd8-6a3b5a5a87e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ade1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6169a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "# changed line:\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48fb96d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7af4b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproducibility \n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d630c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll data\n",
    "path_train ='../Data/dev.conll' #adapt\n",
    "path_eval = '../Data/test.conll' # adapt\n",
    "\n",
    "paths = [path_train, path_eval]\n",
    "\n",
    "# change to test if you are evaluating on test:\n",
    "eval_split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ada55296-d462-4ba3-a1f0-1c64d894932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_emb = '../Model/wiki-news-300d-1M.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b155f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model output path\n",
    "output_path = 'lsmt-out.csv' # adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d45d3",
   "metadata": {},
   "source": [
    "### Data peperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f352eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def convert_data(paths):\n",
    "    data = []\n",
    "    sent_id = 0\n",
    "    \n",
    "    all_dfs = []\n",
    "    \n",
    "    for path in paths:\n",
    "        split = path.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        df = pd.read_csv(path, sep='\\t', header=None, on_bad_lines='skip', engine='python',\n",
    "                         names=[\"id\", \"word\", \"lemma\", \"pos-univ\", \"pos\", \"morph\", \"head\", \"basic_dep\", \"enhanced_dep\" , \"space\", \"predicate\", \"label\"])\n",
    "        # Remove missing values\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Add 'Split' column\n",
    "        df['Split'] = split\n",
    "\n",
    "        # Add 'Sentence #' column\n",
    "        df['Start'] = df['id'].shift(1) >= df['id']\n",
    "        df['Sentence #'] = df['Start'].cumsum() + sent_id\n",
    "        sent_id = df['Sentence #'].iloc[-1]\n",
    "\n",
    "        # Remove the temporary 'Start' column\n",
    "        df = df.drop(columns=['Start'])\n",
    "\n",
    "        # Append DataFrame to the list\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    result = pd.concat(all_dfs, ignore_index=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c86a274",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3528123-3379-442f-9897-c3dc21e2fa68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_             175852\n",
       "V               9777\n",
       "ARG1            6561\n",
       "ARG0            3466\n",
       "ARG2            2338\n",
       "ARGM-TMP        1095\n",
       "ARGM-ADV         977\n",
       "ARGM-MOD         819\n",
       "ARGM-ADJ         479\n",
       "ARGM-LOC         449\n",
       "ARGM-NEG         431\n",
       "ARGM-DIS         368\n",
       "ARGM-MNR         323\n",
       "ARGM-EXT         217\n",
       "ARG3             151\n",
       "ARGM-LVB         144\n",
       "ARGM-PRR         144\n",
       "ARGM-PRP         136\n",
       "R-ARG0           127\n",
       "R-ARG1           118\n",
       "ARGM-CAU         116\n",
       "C-ARG1           105\n",
       "ARG4             103\n",
       "ARGM-DIR          95\n",
       "ARGM-PRD          94\n",
       "ARGM-GOL          50\n",
       "C-V               36\n",
       "ARGM-COM          27\n",
       "ARGM-CXN          26\n",
       "R-ARGM-LOC        19\n",
       "C-ARG2            14\n",
       "C-ARGM-CXN        12\n",
       "R-ARGM-TMP        10\n",
       "R-ARGM-MNR        10\n",
       "C-ARG3             9\n",
       "C-ARG0             7\n",
       "R-ARG2             5\n",
       "ARGM-REC           4\n",
       "C-ARGM-LOC         4\n",
       "R-ARGM-ADV         2\n",
       "ARG5               2\n",
       "C-ARGM-EXT         2\n",
       "ARG1-DSP           2\n",
       "ARGA               2\n",
       "C-ARGM-MNR         1\n",
       "R-ARGM-COM         1\n",
       "R-ARGM-CAU         1\n",
       "R-ARG3             1\n",
       "R-ARGM-ADJ         1\n",
       "R-ARGM-DIR         1\n",
       "C-ARG1-DSP         1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76e75ecc-2926-4937-a6ef-9750e50c35f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length after reading dataset: 81\n",
      "Sentence index: 5037\n",
      "Sentence: ['(', 'You', 'do', \"n't\", 'need', 'to', 'use', 'their', 'site', ',', 'you', 'can', 'opt', '-', 'out', 'of', 'sharing', 'your', 'information', ',', 'you', 'do', \"n't\", 'need', 'to', 'send', 'stuff', 'to', 'anyone', 'with', 'a', 'Gmail', 'account', ',', 'and', 'if', '--', 'wonder', 'of', 'wonders', '--', 'you', \"'re\", 'worried', 'that', 'you', 'might', 'send', 'something', 'to', 'someone', 'who', 'would', 'forward', 'an', 'excerpt', 'to', 'someone', 'who', 'would', 'then', 'store', 'it', 'on', 'a', 'Gmail', 'account', '...', 'you', 'have', 'far', ',', 'far', 'too', 'much', 'time', 'on', 'your', 'hands', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "# Check the lengths of sentences after creating the DataFrame\n",
    "sentences = data.groupby(\"Sentence #\")[\"word\"].apply(list).tolist()\n",
    "sentence_lengths = [len(sentence) for sentence in sentences]\n",
    "\n",
    "max_length = max(sentence_lengths)\n",
    "max_length_idx = sentence_lengths.index(max_length)\n",
    "\n",
    "print(\"Max length after reading dataset:\", max_length)\n",
    "print(\"Sentence index:\", max_length_idx)\n",
    "print(\"Sentence:\", sentences[max_length_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5577919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_map(data, token_or_tag, embedding_model=None):\n",
    "    tok2idx = {}\n",
    "    idx2tok = {}\n",
    "    \n",
    "    if token_or_tag == 'word':\n",
    "        vocab = list(set(data['word'].to_list()))\n",
    "    else:\n",
    "        vocab = list(set(data['label'].to_list()))\n",
    "    \n",
    "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
    "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}   \n",
    "    \n",
    "    return tok2idx, idx2tok\n",
    "\n",
    "\n",
    "token2idx, idx2token = get_dict_map(data, 'word')\n",
    "tag2idx, idx2tag = get_dict_map(data, 'label')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dc9aa27-9f96-4e2e-b241-0fc87b508a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7858\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "n_vocab = len(token2idx)\n",
    "n_tags = len(tag2idx)\n",
    "\n",
    "print(n_vocab)\n",
    "print(n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e947f84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = KeyedVectors.load_word2vec_format(path_emb, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9ee6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7859, 300)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding matrix with zero vectors for oov words\n",
    "emb_dim = 300\n",
    "embedding_matrix = np.zeros((len(token2idx) + 1, emb_dim))\n",
    "print(embedding_matrix.shape)\n",
    "for word, i in token2idx.items():\n",
    "    # You may have to change the following line to:\n",
    "    # if word in w2v_model:\n",
    "    if word in w2v_model.key_to_index:\n",
    "        embedding_vector = w2v_model[word]\n",
    "    else:\n",
    "        embedding_vector = None\n",
    "        # If you want to check OOV words:\n",
    "        #print('couldnt find:', word, i)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c843df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7859, 300)\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "# Check dimensions, store number of vector dimensions in variable\n",
    "print(embedding_matrix.shape)\n",
    "emb_dim = embedding_matrix.shape[1]\n",
    "print(emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24ea6a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos-univ</th>\n",
       "      <th>pos</th>\n",
       "      <th>morph</th>\n",
       "      <th>head</th>\n",
       "      <th>basic_dep</th>\n",
       "      <th>enhanced_dep</th>\n",
       "      <th>space</th>\n",
       "      <th>predicate</th>\n",
       "      <th>label</th>\n",
       "      <th>Split</th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word_idx</th>\n",
       "      <th>Tag_idx</th>\n",
       "      <th>Predicate_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>From</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>3</td>\n",
       "      <td>case</td>\n",
       "      <td>3:case</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Definite=Def|PronType=Art</td>\n",
       "      <td>3</td>\n",
       "      <td>det</td>\n",
       "      <td>3:det</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>3104</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AP</td>\n",
       "      <td>AP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Number=Sing</td>\n",
       "      <td>4</td>\n",
       "      <td>obl</td>\n",
       "      <td>4:obl:from</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>ARG2</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>5161</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>comes</td>\n",
       "      <td>come</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...</td>\n",
       "      <td>0</td>\n",
       "      <td>root</td>\n",
       "      <td>0:root</td>\n",
       "      <td>_</td>\n",
       "      <td>come.03</td>\n",
       "      <td>V</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>897</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>Number=Sing|PronType=Dem</td>\n",
       "      <td>6</td>\n",
       "      <td>det</td>\n",
       "      <td>6:det</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>dev</td>\n",
       "      <td>0</td>\n",
       "      <td>4049</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204720</th>\n",
       "      <td>6</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>SCONJ</td>\n",
       "      <td>IN</td>\n",
       "      <td>_</td>\n",
       "      <td>7</td>\n",
       "      <td>mark</td>\n",
       "      <td>7:mark</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>9770</td>\n",
       "      <td>2227</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204721</th>\n",
       "      <td>7</td>\n",
       "      <td>diagnosing</td>\n",
       "      <td>diagnose</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VerbForm=Ger</td>\n",
       "      <td>5</td>\n",
       "      <td>advcl</td>\n",
       "      <td>5:advcl:in</td>\n",
       "      <td>SpaceAfter=No</td>\n",
       "      <td>diagnose.01</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>9770</td>\n",
       "      <td>7620</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204722</th>\n",
       "      <td>8</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>_</td>\n",
       "      <td>9</td>\n",
       "      <td>punct</td>\n",
       "      <td>9:punct</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>9770</td>\n",
       "      <td>7584</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204723</th>\n",
       "      <td>9</td>\n",
       "      <td>addressing</td>\n",
       "      <td>address</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VerbForm=Ger</td>\n",
       "      <td>7</td>\n",
       "      <td>conj</td>\n",
       "      <td>5:advcl:in|7:conj:and</td>\n",
       "      <td>_</td>\n",
       "      <td>address.02</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>9770</td>\n",
       "      <td>6088</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204724</th>\n",
       "      <td>10</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>CC</td>\n",
       "      <td>_</td>\n",
       "      <td>11</td>\n",
       "      <td>cc</td>\n",
       "      <td>11:cc</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>test</td>\n",
       "      <td>9770</td>\n",
       "      <td>169</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204725 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        word     lemma pos-univ  pos  \\\n",
       "0        1        From      from      ADP   IN   \n",
       "1        2         the       the      DET   DT   \n",
       "2        3          AP        AP    PROPN  NNP   \n",
       "3        4       comes      come     VERB  VBZ   \n",
       "4        5        this      this      DET   DT   \n",
       "...     ..         ...       ...      ...  ...   \n",
       "204720   6          in        in    SCONJ   IN   \n",
       "204721   7  diagnosing  diagnose     VERB  VBG   \n",
       "204722   8           ,         ,    PUNCT    ,   \n",
       "204723   9  addressing   address     VERB  VBG   \n",
       "204724  10         and       and    CCONJ   CC   \n",
       "\n",
       "                                                    morph head basic_dep  \\\n",
       "0                                                       _    3      case   \n",
       "1                               Definite=Def|PronType=Art    3       det   \n",
       "2                                             Number=Sing    4       obl   \n",
       "3       Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbF...    0      root   \n",
       "4                                Number=Sing|PronType=Dem    6       det   \n",
       "...                                                   ...  ...       ...   \n",
       "204720                                                  _    7      mark   \n",
       "204721                                       VerbForm=Ger    5     advcl   \n",
       "204722                                                  _    9     punct   \n",
       "204723                                       VerbForm=Ger    7      conj   \n",
       "204724                                                  _   11        cc   \n",
       "\n",
       "                 enhanced_dep          space    predicate label Split  \\\n",
       "0                      3:case              _            _     _   dev   \n",
       "1                       3:det              _            _     _   dev   \n",
       "2                  4:obl:from              _            _  ARG2   dev   \n",
       "3                      0:root              _      come.03     V   dev   \n",
       "4                       6:det              _            _     _   dev   \n",
       "...                       ...            ...          ...   ...   ...   \n",
       "204720                 7:mark              _            _     _  test   \n",
       "204721             5:advcl:in  SpaceAfter=No  diagnose.01     _  test   \n",
       "204722                9:punct              _            _     _  test   \n",
       "204723  5:advcl:in|7:conj:and              _   address.02     _  test   \n",
       "204724                  11:cc              _            _     _  test   \n",
       "\n",
       "        Sentence #  Word_idx  Tag_idx  Predicate_idx  \n",
       "0                0       417       45              0  \n",
       "1                0      3104       45              0  \n",
       "2                0      5161        9              0  \n",
       "3                0       897       27              1  \n",
       "4                0      4049       45              0  \n",
       "...            ...       ...      ...            ...  \n",
       "204720        9770      2227       45              0  \n",
       "204721        9770      7620       45              0  \n",
       "204722        9770      7584       45              0  \n",
       "204723        9770      6088       45              0  \n",
       "204724        9770       169       45              0  \n",
       "\n",
       "[204725 rows x 17 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add index info to dataframe\n",
    "\n",
    "data['Word_idx'] = data['word'].map(token2idx)\n",
    "data['Tag_idx'] = data['label'].map(tag2idx)\n",
    "data['Predicate_idx'] = data['label'].apply(lambda x: 1 if x == 'V' else 0)\n",
    "data[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49377989-4e32-40e9-9a3e-2b2335a010b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fillna = data.fillna(method='ffill', axis=0)\n",
    "# Groupby and collect columns\n",
    "data_group = data_fillna.groupby(['Sentence #'], as_index=False)[\n",
    "    [\"id\", \"word\", \"lemma\", \"pos-univ\", \"pos\", \"morph\", \"head\", \"basic_dep\", \n",
    "     \"enhanced_dep\", \"space\", \"predicate\", \"label\", 'Word_idx', 'Tag_idx','Predicate_idx', 'Split']\n",
    "].agg(lambda x: list(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34018071-ac91-450d-a37d-cb4d66c0195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "this is maxlen: 81\n",
      "padding 81\n",
      "n_tags: 51\n",
      "train_tokens length: 4799 \n",
      "train_tokens length: 4799 \n",
      "val_tokens: 4972 \n",
      "val_tags: 4972\n"
     ]
    }
   ],
   "source": [
    "# Change eval_split from 'dev' to test to run on test data\n",
    "def get_pad_train_test_val(data_group, data, eval_split='train', n_vocab = n_vocab):\n",
    "\n",
    "    #get max token and tag length\n",
    "    n_token = len(list(set(data['word'].to_list())))\n",
    "    n_tag = len(list(set(data['label'].to_list())))\n",
    "    print(n_tag)\n",
    "\n",
    "    #Pad tokens (X var)    \n",
    "    tokens = data_group['Word_idx'].tolist() \n",
    "    maxlen = max([len(s) for s in tokens])\n",
    "    print (\"this is maxlen:\", maxlen)\n",
    "    # value should be the number of items in the vocb?\n",
    "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int64', padding='post', value= n_vocab)\n",
    "    print('padding', len(pad_tokens[0]))\n",
    "    # I used the code below to check the if the padded vectors are set to 0:\n",
    "#     for token in pad_tokens:\n",
    "#         print(token[-1])\n",
    "# #         print(embedding_matrix[token[-1]])\n",
    "#         break\n",
    "\n",
    "    #Pad Tags (y var) and convert it into one hot encoding\n",
    "    tags = data_group['Tag_idx'].tolist()\n",
    "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int64', padding='post', value= tag2idx[\"R-ARGM-ADJ\"])\n",
    "    n_tags = len(tag2idx)\n",
    "    print (\"n_tags:\",n_tags)\n",
    "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
    "    # Pad predicates\n",
    "    predicates = data_group['Predicate_idx'].tolist()\n",
    "    pad_predicates = pad_sequences(predicates, maxlen=maxlen, dtype='int64', padding='post', value=0)\n",
    "    \n",
    "    train_tokens = []\n",
    "    dev_tokens = []\n",
    "    train_tags = []\n",
    "    dev_tags = []\n",
    "    train_predicates = []\n",
    "    dev_predicates = []\n",
    "\n",
    "    for i, row in data_group.iterrows():\n",
    "        if 'test' in row['Split']:\n",
    "            train_tokens.append(pad_tokens[i])\n",
    "            train_tags.append(pad_tags[i])\n",
    "            train_predicates.append(pad_predicates[i])\n",
    "        elif 'dev' in row['Split']:\n",
    "            dev_tokens.append(pad_tokens[i])\n",
    "            dev_tags.append(pad_tags[i])\n",
    "            dev_predicates.append(pad_predicates[i])\n",
    "\n",
    "    print(\n",
    "        'train_tokens length:', len(train_tokens),\n",
    "        '\\ntrain_tokens length:', len(train_tokens),\n",
    "        #'\\ntest_tokens length:', len(test_tokens),\n",
    "        #'\\ntest_tags:', len(test_tags),\n",
    "        '\\nval_tokens:', len(dev_tokens),\n",
    "        '\\nval_tags:', len(dev_tags))\n",
    " \n",
    "    return np.array(train_tokens), np.array(dev_tokens), np.array(train_predicates), np.array(dev_predicates), np.array(train_tags), np.array(dev_tags)\n",
    "\n",
    "train_tokens, dev_tokens, train_predicates,dev_predicates, train_tags, dev_tags = get_pad_train_test_val(data_group, data, eval_split= eval_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df90e5cc-993a-4e8c-936f-04ec9df87202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_dim:  7859 \n",
      "output_dim:  300 \n",
      "input_length:  81 \n",
      "n_tags:  51\n",
      "emb dim 300\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(list(set(data['word'].to_list()))) +1\n",
    "output_dim = emb_dim # number of dimensions\n",
    "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
    "n_tags = len(tag2idx)\n",
    "print('input_dim: ', \n",
    "      input_dim, '\\noutput_dim: ', \n",
    "      output_dim, '\\ninput_length: ', \n",
    "      input_length, '\\nn_tags: ', n_tags)\n",
    "print('emb dim', emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6525ca-33d5-4eaa-8d53-1ea6c9b71fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bilstm_lstm_model_v2(embedding_matrix, embedding_dim):\n",
    "    word_input = Input(shape=(input_length,), dtype='int32', name='word_input')\n",
    "    predicate_input = Input(shape=(input_length,), dtype='int32', name='predicate_input')\n",
    "\n",
    "    embedding_layer = Embedding(len(token2idx) + 1,\n",
    "                                 embedding_dim,\n",
    "                                 weights=[embedding_matrix],\n",
    "                                 input_length=input_length,\n",
    "                                 trainable=False)(word_input)\n",
    "\n",
    "    predicate_embedding = Embedding(2, embedding_dim, input_length=input_length)(predicate_input)\n",
    "\n",
    "    merged_embeddings = concatenate([embedding_layer, predicate_embedding])\n",
    "\n",
    "    bilstm = Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode='concat')(merged_embeddings)\n",
    "    \n",
    "    output = TimeDistributed(Dense(n_tags, activation=\"softmax\"))(bilstm)\n",
    "\n",
    "    model = Model(inputs=[word_input, predicate_input], outputs=output)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c8f4f-b58f-4a01-9f9b-7c92d2386744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "948f818c-384d-4e7d-83bf-bfbee78fd842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4799, 81, 51)\n",
      "(4972, 81, 51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_tags.shape)\n",
    "print(dev_tags.shape)\n",
    "\n",
    "n_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a821d74-5d0d-47a3-84dd-81e43f1eff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_pred, y, model):\n",
    "    loss = list()\n",
    "    for i in range(8):\n",
    "        hist = model.fit([X, X_pred], y, batch_size=200, verbose=1, epochs=1, validation_split=0.2)\n",
    "        loss.append(hist.history['loss'][0])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "531dd30b-79d7-4d70-a678-28214d99af2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " word_input (InputLayer)        [(None, 81)]         0           []                               \n",
      "                                                                                                  \n",
      " predicate_input (InputLayer)   [(None, 81)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 81, 300)      2357700     ['word_input[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 81, 300)      600         ['predicate_input[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 81, 600)      0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 81, 1200)     5764800     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 81, 600)      4322400     ['bidirectional[0][0]']          \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 81, 51)      30651       ['lstm_1[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,476,151\n",
      "Trainable params: 10,118,451\n",
      "Non-trainable params: 2,357,700\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "embedding_dim = 300 # dimensions of the word2vec vectors\n",
    "model_bilstm_lstm_v2 = get_bilstm_lstm_model_v2(embedding_matrix, embedding_dim)\n",
    "results['with_add_lstm'] = train_model(dev_tokens, dev_predicates, dev_tags, model_bilstm_lstm_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e45b71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 403s 20s/step - loss: 0.9246 - accuracy: 0.8156 - val_loss: 0.2530 - val_accuracy: 0.9481\n",
      "20/20 [==============================] - 430s 22s/step - loss: 0.2273 - accuracy: 0.9544 - val_loss: 0.1818 - val_accuracy: 0.9618\n",
      "20/20 [==============================] - 442s 22s/step - loss: 0.1948 - accuracy: 0.9615 - val_loss: 0.1704 - val_accuracy: 0.9639\n",
      "20/20 [==============================] - 428s 22s/step - loss: 0.1874 - accuracy: 0.9621 - val_loss: 0.1654 - val_accuracy: 0.9640\n",
      "20/20 [==============================] - 401s 20s/step - loss: 0.1826 - accuracy: 0.9624 - val_loss: 0.1606 - val_accuracy: 0.9640\n",
      "20/20 [==============================] - 363s 18s/step - loss: 0.1743 - accuracy: 0.9626 - val_loss: 0.1484 - val_accuracy: 0.9642\n",
      "20/20 [==============================] - 361s 18s/step - loss: 0.1507 - accuracy: 0.9686 - val_loss: 0.1201 - val_accuracy: 0.9758\n",
      "20/20 [==============================] - 341s 17s/step - loss: 0.1262 - accuracy: 0.9749 - val_loss: 0.1073 - val_accuracy: 0.9765\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1769f23-6a1f-4ce1-8dd7-e4b13432f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Evaluate on test data\")\n",
    "# results = model_bilstm_lstm_v2.evaluate([dev_tokens, dev_predicates], np.array(dev_tags), batch_size=1)\n",
    "# print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19893a1f-b05d-42d2-968d-7e02fbcd06e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 239s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_bilstm_lstm_v2.predict([train_tokens, train_predicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4dfe9253-6f98-48ce-a53b-46aaa1cbfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4799\n"
     ]
    }
   ],
   "source": [
    "# get dimension index with highest prob (--> label)\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "y_dev =  np.argmax(dev_tags, axis=-1)\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04c72449-7b19-4b91-8d13-cb3e7a5d2be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ARG0       0.00      0.00      0.00     405.0\n",
      "        ARG1       0.00      0.00      0.00     329.0\n",
      "        ARG2       0.00      0.00      0.00      18.0\n",
      "        ARG3       0.00      0.00      0.00       2.0\n",
      "    ARGM-ADJ       0.00      0.00      0.00      30.0\n",
      "    ARGM-ADV       0.00      0.00      0.00      42.0\n",
      "    ARGM-CAU       0.00      0.00      0.00      11.0\n",
      "    ARGM-DIS       0.00      0.00      0.00      89.0\n",
      "    ARGM-EXT       0.00      0.00      0.00       4.0\n",
      "    ARGM-LOC       0.00      0.00      0.00       5.0\n",
      "    ARGM-LVB       0.00      0.00      0.00       8.0\n",
      "    ARGM-MNR       0.00      0.00      0.00      14.0\n",
      "    ARGM-MOD       0.00      0.00      0.00      21.0\n",
      "    ARGM-NEG       0.00      0.00      0.00       4.0\n",
      "    ARGM-PRD       0.00      0.00      0.00       2.0\n",
      "    ARGM-TMP       0.00      0.00      0.00      19.0\n",
      "  C-ARGM-CXN       0.00      0.00      0.00       0.0\n",
      "  R-ARGM-LOC       0.00      0.00      0.00       0.0\n",
      "           V       0.00      0.00      0.00     218.0\n",
      "           _       0.00      0.00      0.00    3578.0\n",
      "\n",
      "    accuracy                           0.00    4799.0\n",
      "   macro avg       0.00      0.00      0.00    4799.0\n",
      "weighted avg       0.00      0.00      0.00    4799.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Convert the predictions and true labels to their original tag forms (not one-hot encoded)\n",
    "predicted_tags = np.argmax(y_pred, axis=-1)\n",
    "true_tags = np.argmax(np.array(dev_tags), axis=-1)\n",
    "\n",
    "# Create a reverse mapping from tag indices to tag names\n",
    "idx2tag = {i: tag for tag, i in tag2idx.items()}\n",
    "\n",
    "predicted_tags_names = []\n",
    "true_tags_names = []\n",
    "\n",
    "for true_seq, pred_seq in zip(true_tags, predicted_tags):\n",
    "    for true_tag, pred_tag in zip(true_seq.ravel(), pred_seq.ravel()):\n",
    "        # Ignore padding values when both true_tag and pred_tag are padding tags\n",
    "        #if not (true_tag == tag2idx[\"R-ARGM-ADJ\"] and pred_tag == tag2idx[\"R-ARGM-ADJ\"]):\n",
    "            predicted_tags_names.append(idx2tag[pred_tag])\n",
    "            true_tags_names.append(idx2tag[true_tag])\n",
    "\n",
    "# Generate the classification report\n",
    "report = classification_report(true_tags_names, predicted_tags_names, zero_division=0)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "570f59ed-5e19-4859-a51a-1c52180487df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_tags_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64e5e8bd-ca9e-4bc7-ab03-b23e505b0ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'C-ARGM-CXN': 4568, 'R-ARGM-LOC': 231})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "my_counter = Counter(predicted_tags_names)\n",
    "my_counter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
